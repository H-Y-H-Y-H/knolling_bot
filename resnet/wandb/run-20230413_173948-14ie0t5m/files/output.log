Device: cuda:1
this is num of close 1000
this is num of normal 1000
begin!
Training_Loss At Epoch 0:	0.06794220949523151
Testing_Loss At Epoch 0:	0.08591138299554586
0 time used:  153.32581615447998 lr: [0.0001]
Training_Loss At Epoch 1:	0.054971627974882725
Testing_Loss At Epoch 1:	0.06151819031685591
1 time used:  159.98291110992432 lr: [0.0001]
Training_Loss At Epoch 2:	0.050085750413127246
Testing_Loss At Epoch 2:	0.046553950570523736
2 time used:  162.48823046684265 lr: [0.0001]
3 time used:  162.83379340171814 lr: [0.0001]
4 time used:  163.64858627319336 lr: [0.0001]
Training_Loss At Epoch 5:	0.04338683406356722
Testing_Loss At Epoch 5:	0.04450763452798128
5 time used:  163.29748463630676 lr: [0.0001]
Training_Loss At Epoch 6:	0.0413529862370342
Testing_Loss At Epoch 6:	0.041427867487072945
6 time used:  162.7018756866455 lr: [0.0001]
7 time used:  162.7997829914093 lr: [0.0001]
8 time used:  163.25103783607483 lr: [0.0001]
9 time used:  163.72341346740723 lr: [0.0001]
Training_Loss At Epoch 10:	0.038394801006652414
Testing_Loss At Epoch 10:	0.039831250701099635
10 time used:  166.78198194503784 lr: [0.0001]
11 time used:  169.08660674095154 lr: [1e-05]
Training_Loss At Epoch 12:	0.03697073768824339
Testing_Loss At Epoch 12:	0.03797107703983784
12 time used:  169.63706254959106 lr: [1e-05]
Training_Loss At Epoch 13:	0.036164864702150225
Testing_Loss At Epoch 13:	0.037481829281896355
13 time used:  169.5672435760498 lr: [1e-05]
14 time used:  169.22332882881165 lr: [1e-05]
Training_Loss At Epoch 15:	0.03536964046536013
Testing_Loss At Epoch 15:	0.036883334517478945
15 time used:  169.39982104301453 lr: [1e-05]
16 time used:  164.82754373550415 lr: [1e-05]
17 time used:  163.34709191322327 lr: [1e-05]
18 time used:  164.32970118522644 lr: [1e-05]
Training_Loss At Epoch 19:	0.034320139046758416
Testing_Loss At Epoch 19:	0.036347281895577906
19 time used:  169.32460618019104 lr: [1e-05]
Training_Loss At Epoch 20:	0.03410217850469053
Testing_Loss At Epoch 20:	0.03615639480762184
20 time used:  164.68286848068237 lr: [1e-05]
Training_Loss At Epoch 21:	0.03394330893643201
Testing_Loss At Epoch 21:	0.03596284244209528
21 time used:  164.31483793258667 lr: [1e-05]
22 time used:  164.7795765399933 lr: [1e-05]
23 time used:  164.75912022590637 lr: [1.0000000000000002e-06]
Training_Loss At Epoch 24:	0.03306315860245377
Testing_Loss At Epoch 24:	0.03582780594006181
24 time used:  165.05270171165466 lr: [1.0000000000000002e-06]
25 time used:  164.20768237113953 lr: [1.0000000000000002e-06]
Training_Loss At Epoch 26:	0.03293505850248039
Testing_Loss At Epoch 26:	0.03567938934080303
26 time used:  164.71020531654358 lr: [1.0000000000000002e-06]
Training_Loss At Epoch 27:	0.03289414300583303
Testing_Loss At Epoch 27:	0.0356679387204349
27 time used:  166.75912046432495 lr: [1.0000000000000002e-06]
Training_Loss At Epoch 28:	0.03286015761317685
Testing_Loss At Epoch 28:	0.03562479861080647
28 time used:  169.73419284820557 lr: [1.0000000000000002e-06]
Training_Loss At Epoch 29:	0.032819883397314696
Testing_Loss At Epoch 29:	0.0355991031229496
29 time used:  167.48925924301147 lr: [1.0000000000000002e-06]
30 time used:  169.41266226768494 lr: [1.0000000000000002e-06]
31 time used:  169.57665729522705 lr: [1.0000000000000002e-06]
Training_Loss At Epoch 32:	0.032707025692798194
Testing_Loss At Epoch 32:	0.0355346136726439
32 time used:  170.3794469833374 lr: [1.0000000000000002e-06]
33 time used:  169.69672107696533 lr: [1.0000000000000002e-06]
